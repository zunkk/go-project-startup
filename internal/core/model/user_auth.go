// Code generated by SQLBoiler 4.18.0 (https://github.com/volatiletech/sqlboiler). DO NOT EDIT.
// This file is meant to be re-generated in place and/or deleted at any time.

package model

import (
	"context"
	"database/sql"
	"fmt"
	"reflect"
	"strconv"
	"strings"
	"sync"
	"time"

	"github.com/friendsofgo/errors"
	"github.com/volatiletech/sqlboiler/v4/boil"
	"github.com/volatiletech/sqlboiler/v4/queries"
	"github.com/volatiletech/sqlboiler/v4/queries/qm"
	"github.com/volatiletech/sqlboiler/v4/queries/qmhelper"
	"github.com/volatiletech/strmangle"
)

// /////////////////////////////// BEGIN EXTENSIONS /////////////////////////////////
// Expose table columns
var (
	UserAuthAllColumns            = userAuthAllColumns
	UserAuthColumnsWithoutDefault = userAuthColumnsWithoutDefault
	UserAuthColumnsWithDefault    = userAuthColumnsWithDefault
	UserAuthPrimaryKeyColumns     = userAuthPrimaryKeyColumns
	UserAuthGeneratedColumns      = userAuthGeneratedColumns
)

// GetID get ID from model object
func (o *UserAuth) GetID() int64 {
	return o.ID
}

// GetIDs extract IDs from model objects
func (s UserAuthSlice) GetIDs() []int64 {
	result := make([]int64, len(s))
	for i := range s {
		result[i] = s[i].ID
	}
	return result
}

// GetIntfIDs extract IDs from model objects as interface slice
func (s UserAuthSlice) GetIntfIDs() []interface{} {
	result := make([]interface{}, len(s))
	for i := range s {
		result[i] = s[i].ID
	}
	return result
}

// ToIDMap convert a slice of model objects to a map with ID as key
func (s UserAuthSlice) ToIDMap() map[int64]*UserAuth {
	result := make(map[int64]*UserAuth, len(s))
	for _, o := range s {
		result[o.ID] = o
	}
	return result
}

// ToUniqueItems construct a slice of unique items from the given slice
func (s UserAuthSlice) ToUniqueItems() UserAuthSlice {
	result := make(UserAuthSlice, 0, len(s))
	mapChk := make(map[int64]struct{}, len(s))
	for i := len(s) - 1; i >= 0; i-- {
		o := s[i]
		if _, ok := mapChk[o.ID]; !ok {
			mapChk[o.ID] = struct{}{}
			result = append(result, o)
		}
	}
	return result
}

// FindItemByID find item by ID in the slice
func (s UserAuthSlice) FindItemByID(id int64) *UserAuth {
	for _, o := range s {
		if o.ID == id {
			return o
		}
	}
	return nil
}

// FindMissingItemIDs find all item IDs that are not in the list
// NOTE: the input ID slice should contain unique values
func (s UserAuthSlice) FindMissingItemIDs(expectedIDs []int64) []int64 {
	if len(s) == 0 {
		return expectedIDs
	}
	result := []int64{}
	mapChk := s.ToIDMap()
	for _, id := range expectedIDs {
		if _, ok := mapChk[id]; !ok {
			result = append(result, id)
		}
	}
	return result
}

// InsertAll inserts all rows with the specified column values, using an executor.
// IMPORTANT: this will calculate the widest columns from all items in the slice, be careful if you want to use default column values
func (o UserAuthSlice) InsertAll(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) (int64, error) {
	if len(o) == 0 {
		return 0, nil
	}

	// Calculate the widest columns from all rows need to insert
	wlCols := make(map[string]struct{}, 10)
	for _, row := range o {
		wl, _ := columns.InsertColumnSet(
			userAuthAllColumns,
			userAuthColumnsWithDefault,
			userAuthColumnsWithoutDefault,
			queries.NonZeroDefaultSet(userAuthColumnsWithDefault, row),
		)
		for _, col := range wl {
			wlCols[col] = struct{}{}
		}
	}
	wl := make([]string, 0, len(wlCols))
	for _, col := range userAuthAllColumns {
		if _, ok := wlCols[col]; ok {
			wl = append(wl, col)
		}
	}

	var sql string
	vals := []interface{}{}
	for i, row := range o {

		if i == 0 {
			sql = "INSERT INTO \"user_auth\" " + "(\"" + strings.Join(wl, "\",\"") + "\")" + " VALUES "
		}
		sql += strmangle.Placeholders(dialect.UseIndexPlaceholders, len(wl), len(vals)+1, len(wl))
		if i != len(o)-1 {
			sql += ","
		}
		valMapping, err := queries.BindMapping(userAuthType, userAuthMapping, wl)
		if err != nil {
			return 0, err
		}

		value := reflect.Indirect(reflect.ValueOf(row))
		vals = append(vals, queries.ValuesFromMapping(value, valMapping)...)
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, vals)
	}

	result, err := exec.ExecContext(ctx, sql, vals...)
	if err != nil {
		return 0, errors.Wrap(err, "model: unable to insert all from userAuth slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "model: failed to get rows affected by insertall for user_auth")
	}

	return rowsAff, nil
}

// InsertIgnoreAll inserts all rows with ignoring the existing ones having the same primary key values.
// NOTE: This function calls UpsertAll() with updateOnConflict=false and conflictColumns=<primary key columns>
// IMPORTANT: this will calculate the widest columns from all items in the slice, be careful if you want to use default column values
// IMPORTANT: if the table has `id` column of auto-increment type, this may not work as expected
func (o UserAuthSlice) InsertIgnoreAll(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) (int64, error) {
	return o.UpsertAll(ctx, exec, false, userAuthPrimaryKeyColumns, boil.None(), columns)
}

// UpsertAll inserts or updates all rows
// Currently it doesn't support "NoContext" and "NoRowsAffected"
// IMPORTANT: this will calculate the widest columns from all items in the slice, be careful if you want to use default column values
// IMPORTANT: if the table has `id` column of auto-increment type, this may not work as expected
func (o UserAuthSlice) UpsertAll(ctx context.Context, exec boil.ContextExecutor, updateOnConflict bool, conflictColumns []string, updateColumns, insertColumns boil.Columns) (int64, error) {
	if len(o) == 0 {
		return 0, nil
	}

	// Calculate the widest columns from all rows need to upsert
	insertCols := make(map[string]struct{}, 10)
	for _, row := range o {
		insert, _ := insertColumns.InsertColumnSet(
			userAuthAllColumns,
			userAuthColumnsWithDefault,
			userAuthColumnsWithoutDefault,
			queries.NonZeroDefaultSet(userAuthColumnsWithDefault, row),
		)
		for _, col := range insert {
			insertCols[col] = struct{}{}
		}
	}
	insert := make([]string, 0, len(insertCols))
	for _, col := range userAuthAllColumns {
		if _, ok := insertCols[col]; ok {
			insert = append(insert, col)
		}
	}

	update := updateColumns.UpdateColumnSet(
		userAuthAllColumns,
		userAuthPrimaryKeyColumns,
	)

	if updateOnConflict && len(update) == 0 {
		return 0, errors.New("model: unable to upsert user_auth, could not build update column list")
	}

	conflict := conflictColumns
	if len(conflict) == 0 {
		conflict = make([]string, len(userAuthPrimaryKeyColumns))
		copy(conflict, userAuthPrimaryKeyColumns)
	}

	buf := strmangle.GetBuffer()
	defer strmangle.PutBuffer(buf)

	columns := "DEFAULT VALUES"
	if len(insert) != 0 {
		columns = fmt.Sprintf("(%s) VALUES %s",
			strings.Join(insert, ", "),
			strmangle.Placeholders(dialect.UseIndexPlaceholders, len(insert)*len(o), 1, len(insert)),
		)
	}

	fmt.Fprintf(
		buf,
		"INSERT INTO %s %s ON CONFLICT ",
		"\"user_auth\"",
		columns,
	)

	if !updateOnConflict || len(update) == 0 {
		buf.WriteString("DO NOTHING")
	} else {
		buf.WriteByte('(')
		buf.WriteString(strings.Join(conflict, ", "))
		buf.WriteString(") DO UPDATE SET ")

		for i, v := range update {
			if i != 0 {
				buf.WriteByte(',')
			}
			quoted := strmangle.IdentQuote(dialect.LQ, dialect.RQ, v)
			buf.WriteString(quoted)
			buf.WriteString(" = EXCLUDED.")
			buf.WriteString(quoted)
		}
	}

	query := buf.String()
	valueMapping, err := queries.BindMapping(userAuthType, userAuthMapping, insert)
	if err != nil {
		return 0, err
	}

	var vals []interface{}
	for _, row := range o {

		value := reflect.Indirect(reflect.ValueOf(row))
		vals = append(vals, queries.ValuesFromMapping(value, valueMapping)...)
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, query)
		fmt.Fprintln(writer, vals)
	}

	result, err := exec.ExecContext(ctx, query, vals...)
	if err != nil {
		return 0, errors.Wrap(err, "model: unable to upsert for user_auth")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "model: failed to get rows affected by upsert for user_auth")
	}

	return rowsAff, nil
}

// DeleteAllByPage delete all UserAuth records from the slice.
// This function deletes data by pages to avoid exceeding Postgres limitation (max parameters: 65535)
func (s UserAuthSlice) DeleteAllByPage(ctx context.Context, exec boil.ContextExecutor, limits ...int) (int64, error) {
	length := len(s)
	if length == 0 {
		return 0, nil
	}

	// max number of parameters = 65535
	chunkSize := DefaultPageSize
	if len(limits) > 0 && limits[0] > 0 && limits[0] <= MaxPageSize {
		chunkSize = limits[0]
	}
	if length <= chunkSize {
		return s.DeleteAll(ctx, exec)
	}

	rowsAffected := int64(0)
	start := 0
	for {
		end := start + chunkSize
		if end > length {
			end = length
		}
		rows, err := s[start:end].DeleteAll(ctx, exec)
		if err != nil {
			return rowsAffected, err
		}

		rowsAffected += rows
		start = end
		if start >= length {
			break
		}
	}
	return rowsAffected, nil
}

// UpdateAllByPage update all UserAuth records from the slice.
// This function updates data by pages to avoid exceeding Postgres limitation (max parameters: 65535)
func (s UserAuthSlice) UpdateAllByPage(ctx context.Context, exec boil.ContextExecutor, cols M, limits ...int) (int64, error) {
	length := len(s)
	if length == 0 {
		return 0, nil
	}

	// max number of parameters = 65535
	// NOTE: len(cols) should not be too big
	chunkSize := DefaultPageSize
	if len(limits) > 0 && limits[0] > 0 && limits[0] <= MaxPageSize {
		chunkSize = limits[0]
	}
	if length <= chunkSize {
		return s.UpdateAll(ctx, exec, cols)
	}

	rowsAffected := int64(0)
	start := 0
	for {
		end := start + chunkSize
		if end > length {
			end = length
		}
		rows, err := s[start:end].UpdateAll(ctx, exec, cols)
		if err != nil {
			return rowsAffected, err
		}

		rowsAffected += rows
		start = end
		if start >= length {
			break
		}
	}
	return rowsAffected, nil
}

// InsertAllByPage insert all UserAuth records from the slice.
// This function inserts data by pages to avoid exceeding Postgres limitation (max parameters: 65535)
func (s UserAuthSlice) InsertAllByPage(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns, limits ...int) (int64, error) {
	length := len(s)
	if length == 0 {
		return 0, nil
	}

	// max number of parameters = 65535
	chunkSize := MaxPageSize / reflect.ValueOf(&UserAuthColumns).Elem().NumField()
	if len(limits) > 0 && limits[0] > 0 && limits[0] < chunkSize {
		chunkSize = limits[0]
	}
	if length <= chunkSize {
		return s.InsertAll(ctx, exec, columns)
	}

	rowsAffected := int64(0)
	start := 0
	for {
		end := start + chunkSize
		if end > length {
			end = length
		}
		rows, err := s[start:end].InsertAll(ctx, exec, columns)
		if err != nil {
			return rowsAffected, err
		}

		rowsAffected += rows
		start = end
		if start >= length {
			break
		}
	}
	return rowsAffected, nil
}

// InsertIgnoreAllByPage insert all UserAuth records from the slice.
// This function inserts data by pages to avoid exceeding Postgres limitation (max parameters: 65535)
func (s UserAuthSlice) InsertIgnoreAllByPage(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns, limits ...int) (int64, error) {
	length := len(s)
	if length == 0 {
		return 0, nil
	}

	// max number of parameters = 65535
	chunkSize := MaxPageSize / reflect.ValueOf(&UserAuthColumns).Elem().NumField()
	if len(limits) > 0 && limits[0] > 0 && limits[0] < chunkSize {
		chunkSize = limits[0]
	}
	if length <= chunkSize {
		return s.InsertIgnoreAll(ctx, exec, columns)
	}

	rowsAffected := int64(0)
	start := 0
	for {
		end := start + chunkSize
		if end > length {
			end = length
		}
		rows, err := s[start:end].InsertIgnoreAll(ctx, exec, columns)
		if err != nil {
			return rowsAffected, err
		}

		rowsAffected += rows
		start = end
		if start >= length {
			break
		}
	}
	return rowsAffected, nil
}

// UpsertAllByPage upsert all UserAuth records from the slice.
// This function upserts data by pages to avoid exceeding Postgres limitation (max parameters: 65535)
func (s UserAuthSlice) UpsertAllByPage(ctx context.Context, exec boil.ContextExecutor, updateOnConflict bool, conflictColumns []string, updateColumns, insertColumns boil.Columns, limits ...int) (int64, error) {
	length := len(s)
	if length == 0 {
		return 0, nil
	}

	// max number of parameters = 65535
	chunkSize := MaxPageSize / reflect.ValueOf(&UserAuthColumns).Elem().NumField()
	if len(limits) > 0 && limits[0] > 0 && limits[0] < chunkSize {
		chunkSize = limits[0]
	}
	if length <= chunkSize {
		return s.UpsertAll(ctx, exec, updateOnConflict, conflictColumns, updateColumns, insertColumns)
	}

	rowsAffected := int64(0)
	start := 0
	for {
		end := start + chunkSize
		if end > length {
			end = length
		}
		rows, err := s[start:end].UpsertAll(ctx, exec, updateOnConflict, conflictColumns, updateColumns, insertColumns)
		if err != nil {
			return rowsAffected, err
		}

		rowsAffected += rows
		start = end
		if start >= length {
			break
		}
	}
	return rowsAffected, nil
}

///////////////////////////////// END EXTENSIONS /////////////////////////////////

// Upsert attempts an insert using an executor, and does an update or ignore on conflict.
// See boil.Columns documentation for how to properly use updateColumns and insertColumns.
func (o *UserAuth) Upsert(ctx context.Context, exec boil.ContextExecutor, updateOnConflict bool, conflictColumns []string, updateColumns, insertColumns boil.Columns, opts ...UpsertOptionFunc) error {
	if o == nil {
		return errors.New("model: no user_auth provided for upsert")
	}

	nzDefaults := queries.NonZeroDefaultSet(userAuthColumnsWithDefault, o)

	// Build cache key in-line uglily - mysql vs psql problems
	buf := strmangle.GetBuffer()
	if updateOnConflict {
		buf.WriteByte('t')
	} else {
		buf.WriteByte('f')
	}
	buf.WriteByte('.')
	for _, c := range conflictColumns {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(updateColumns.Kind))
	for _, c := range updateColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	buf.WriteString(strconv.Itoa(insertColumns.Kind))
	for _, c := range insertColumns.Cols {
		buf.WriteString(c)
	}
	buf.WriteByte('.')
	for _, c := range nzDefaults {
		buf.WriteString(c)
	}
	key := buf.String()
	strmangle.PutBuffer(buf)

	userAuthUpsertCacheMut.RLock()
	cache, cached := userAuthUpsertCache[key]
	userAuthUpsertCacheMut.RUnlock()

	var err error

	if !cached {
		insert, _ := insertColumns.InsertColumnSet(
			userAuthAllColumns,
			userAuthColumnsWithDefault,
			userAuthColumnsWithoutDefault,
			nzDefaults,
		)

		update := updateColumns.UpdateColumnSet(
			userAuthAllColumns,
			userAuthPrimaryKeyColumns,
		)

		if updateOnConflict && len(update) == 0 {
			return errors.New("model: unable to upsert user_auth, could not build update column list")
		}

		ret := strmangle.SetComplement(userAuthAllColumns, strmangle.SetIntersect(insert, update))

		conflict := conflictColumns
		if len(conflict) == 0 && updateOnConflict && len(update) != 0 {
			if len(userAuthPrimaryKeyColumns) == 0 {
				return errors.New("model: unable to upsert user_auth, could not build conflict column list")
			}

			conflict = make([]string, len(userAuthPrimaryKeyColumns))
			copy(conflict, userAuthPrimaryKeyColumns)
		}
		cache.query = buildUpsertQueryPostgres(dialect, "\"user_auth\"", updateOnConflict, ret, update, conflict, insert, opts...)

		cache.valueMapping, err = queries.BindMapping(userAuthType, userAuthMapping, insert)
		if err != nil {
			return err
		}
		if len(ret) != 0 {
			cache.retMapping, err = queries.BindMapping(userAuthType, userAuthMapping, ret)
			if err != nil {
				return err
			}
		}
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)
	var returns []interface{}
	if len(cache.retMapping) != 0 {
		returns = queries.PtrsFromMapping(value, cache.retMapping)
	}

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}
	if len(cache.retMapping) != 0 {
		err = exec.QueryRowContext(ctx, cache.query, vals...).Scan(returns...)
		if errors.Is(err, sql.ErrNoRows) {
			err = nil // Postgres doesn't return anything when there's no update
		}
	} else {
		_, err = exec.ExecContext(ctx, cache.query, vals...)
	}
	if err != nil {
		return errors.Wrap(err, "model: unable to upsert user_auth")
	}

	if !cached {
		userAuthUpsertCacheMut.Lock()
		userAuthUpsertCache[key] = cache
		userAuthUpsertCacheMut.Unlock()
	}

	return nil
}

// UserAuth is an object representing the database table.
type UserAuth struct {
	ID            int64     `csv:"id" boil:"id" json:"id" toml:"id" yaml:"id"`
	CreateTime    time.Time `csv:"create_time" boil:"create_time" json:"create_time" toml:"create_time" yaml:"create_time"`
	UpdateTime    time.Time `csv:"update_time" boil:"update_time" json:"update_time" toml:"update_time" yaml:"update_time"`
	DeleteTime    time.Time `csv:"delete_time" boil:"delete_time" json:"delete_time" toml:"delete_time" yaml:"delete_time"`
	DelState      int64     `csv:"del_state" boil:"del_state" json:"del_state" toml:"del_state" yaml:"del_state"`
	Version       int64     `csv:"version" boil:"version" json:"version" toml:"version" yaml:"version"`
	UserID        int64     `csv:"user_id" boil:"user_id" json:"user_id" toml:"user_id" yaml:"user_id"`
	AuthType      string    `csv:"auth_type" boil:"auth_type" json:"auth_type" toml:"auth_type" yaml:"auth_type"`
	AuthID        string    `csv:"auth_id" boil:"auth_id" json:"auth_id" toml:"auth_id" yaml:"auth_id"`
	AuthToken     string    `csv:"auth_token" boil:"auth_token" json:"auth_token" toml:"auth_token" yaml:"auth_token"`
	LastLoginTime time.Time `csv:"last_login_time" boil:"last_login_time" json:"last_login_time" toml:"last_login_time" yaml:"last_login_time"`

	R *userAuthR `csv:"-" boil:"-" json:"-" toml:"-" yaml:"-"`
	L userAuthL  `csv:"-" boil:"-" json:"-" toml:"-" yaml:"-"`
}

var UserAuthColumns = struct {
	ID            string
	CreateTime    string
	UpdateTime    string
	DeleteTime    string
	DelState      string
	Version       string
	UserID        string
	AuthType      string
	AuthID        string
	AuthToken     string
	LastLoginTime string
}{
	ID:            "id",
	CreateTime:    "create_time",
	UpdateTime:    "update_time",
	DeleteTime:    "delete_time",
	DelState:      "del_state",
	Version:       "version",
	UserID:        "user_id",
	AuthType:      "auth_type",
	AuthID:        "auth_id",
	AuthToken:     "auth_token",
	LastLoginTime: "last_login_time",
}

var UserAuthTableColumns = struct {
	ID            string
	CreateTime    string
	UpdateTime    string
	DeleteTime    string
	DelState      string
	Version       string
	UserID        string
	AuthType      string
	AuthID        string
	AuthToken     string
	LastLoginTime string
}{
	ID:            "user_auth.id",
	CreateTime:    "user_auth.create_time",
	UpdateTime:    "user_auth.update_time",
	DeleteTime:    "user_auth.delete_time",
	DelState:      "user_auth.del_state",
	Version:       "user_auth.version",
	UserID:        "user_auth.user_id",
	AuthType:      "user_auth.auth_type",
	AuthID:        "user_auth.auth_id",
	AuthToken:     "user_auth.auth_token",
	LastLoginTime: "user_auth.last_login_time",
}

// Generated where

var UserAuthWhere = struct {
	ID            whereHelperint64
	CreateTime    whereHelpertime_Time
	UpdateTime    whereHelpertime_Time
	DeleteTime    whereHelpertime_Time
	DelState      whereHelperint64
	Version       whereHelperint64
	UserID        whereHelperint64
	AuthType      whereHelperstring
	AuthID        whereHelperstring
	AuthToken     whereHelperstring
	LastLoginTime whereHelpertime_Time
}{
	ID:            whereHelperint64{field: "\"user_auth\".\"id\""},
	CreateTime:    whereHelpertime_Time{field: "\"user_auth\".\"create_time\""},
	UpdateTime:    whereHelpertime_Time{field: "\"user_auth\".\"update_time\""},
	DeleteTime:    whereHelpertime_Time{field: "\"user_auth\".\"delete_time\""},
	DelState:      whereHelperint64{field: "\"user_auth\".\"del_state\""},
	Version:       whereHelperint64{field: "\"user_auth\".\"version\""},
	UserID:        whereHelperint64{field: "\"user_auth\".\"user_id\""},
	AuthType:      whereHelperstring{field: "\"user_auth\".\"auth_type\""},
	AuthID:        whereHelperstring{field: "\"user_auth\".\"auth_id\""},
	AuthToken:     whereHelperstring{field: "\"user_auth\".\"auth_token\""},
	LastLoginTime: whereHelpertime_Time{field: "\"user_auth\".\"last_login_time\""},
}

// UserAuthRels is where relationship names are stored.
var UserAuthRels = struct {
}{}

// userAuthR is where relationships are stored.
type userAuthR struct {
}

// NewStruct creates a new relationship struct
func (*userAuthR) NewStruct() *userAuthR {
	return &userAuthR{}
}

// userAuthL is where Load methods for each relationship are stored.
type userAuthL struct{}

var (
	userAuthAllColumns            = []string{"id", "create_time", "update_time", "delete_time", "del_state", "version", "user_id", "auth_type", "auth_id", "auth_token", "last_login_time"}
	userAuthColumnsWithoutDefault = []string{"id", "create_time", "update_time", "delete_time", "last_login_time"}
	userAuthColumnsWithDefault    = []string{"del_state", "version", "user_id", "auth_type", "auth_id", "auth_token"}
	userAuthPrimaryKeyColumns     = []string{"id"}
	userAuthGeneratedColumns      = []string{}
)

type (
	// UserAuthSlice is an alias for a slice of pointers to UserAuth.
	// This should almost always be used instead of []UserAuth.
	UserAuthSlice []*UserAuth

	userAuthQuery struct {
		*queries.Query
	}
)

// Cache for insert, update and upsert
var (
	userAuthType                 = reflect.TypeOf(&UserAuth{})
	userAuthMapping              = queries.MakeStructMapping(userAuthType)
	userAuthPrimaryKeyMapping, _ = queries.BindMapping(userAuthType, userAuthMapping, userAuthPrimaryKeyColumns)
	userAuthInsertCacheMut       sync.RWMutex
	userAuthInsertCache          = make(map[string]insertCache)
	userAuthUpdateCacheMut       sync.RWMutex
	userAuthUpdateCache          = make(map[string]updateCache)
	userAuthUpsertCacheMut       sync.RWMutex
	userAuthUpsertCache          = make(map[string]insertCache)
)

var (
	// Force time package dependency for automated UpdatedAt/CreatedAt.
	_ = time.Second
	// Force qmhelper dependency for where clause generation (which doesn't
	// always happen)
	_ = qmhelper.Where
)

// One returns a single userAuth record from the query.
func (q userAuthQuery) One(ctx context.Context, exec boil.ContextExecutor) (*UserAuth, error) {
	o := &UserAuth{}

	queries.SetLimit(q.Query, 1)

	err := q.Bind(ctx, exec, o)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "model: failed to execute a one query for user_auth")
	}

	return o, nil
}

// All returns all UserAuth records from the query.
func (q userAuthQuery) All(ctx context.Context, exec boil.ContextExecutor) (UserAuthSlice, error) {
	var o []*UserAuth

	err := q.Bind(ctx, exec, &o)
	if err != nil {
		return nil, errors.Wrap(err, "model: failed to assign all query results to UserAuth slice")
	}

	return o, nil
}

// Count returns the count of all UserAuth records in the query.
func (q userAuthQuery) Count(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return 0, errors.Wrap(err, "model: failed to count user_auth rows")
	}

	return count, nil
}

// Exists checks if the row exists in the table.
func (q userAuthQuery) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	var count int64

	queries.SetSelect(q.Query, nil)
	queries.SetCount(q.Query)
	queries.SetLimit(q.Query, 1)

	err := q.Query.QueryRowContext(ctx, exec).Scan(&count)
	if err != nil {
		return false, errors.Wrap(err, "model: failed to check if user_auth exists")
	}

	return count > 0, nil
}

// UserAuths retrieves all the records using an executor.
func UserAuths(mods ...qm.QueryMod) userAuthQuery {
	mods = append(mods, qm.From("\"user_auth\""))
	q := NewQuery(mods...)
	if len(queries.GetSelect(q)) == 0 {
		queries.SetSelect(q, []string{"\"user_auth\".*"})
	}

	return userAuthQuery{q}
}

// FindUserAuth retrieves a single record by ID with an executor.
// If selectCols is empty Find will return all columns.
func FindUserAuth(ctx context.Context, exec boil.ContextExecutor, iD int64, selectCols ...string) (*UserAuth, error) {
	userAuthObj := &UserAuth{}

	sel := "*"
	if len(selectCols) > 0 {
		sel = strings.Join(strmangle.IdentQuoteSlice(dialect.LQ, dialect.RQ, selectCols), ",")
	}
	query := fmt.Sprintf(
		"select %s from \"user_auth\" where \"id\"=$1", sel,
	)

	q := queries.Raw(query, iD)

	err := q.Bind(ctx, exec, userAuthObj)
	if err != nil {
		if errors.Is(err, sql.ErrNoRows) {
			return nil, sql.ErrNoRows
		}
		return nil, errors.Wrap(err, "model: unable to select from user_auth")
	}

	return userAuthObj, nil
}

// Insert a single record using an executor.
// See boil.Columns.InsertColumnSet documentation to understand column list inference for inserts.
func (o *UserAuth) Insert(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) error {
	if o == nil {
		return errors.New("model: no user_auth provided for insertion")
	}

	var err error

	nzDefaults := queries.NonZeroDefaultSet(userAuthColumnsWithDefault, o)

	key := makeCacheKey(columns, nzDefaults)
	userAuthInsertCacheMut.RLock()
	cache, cached := userAuthInsertCache[key]
	userAuthInsertCacheMut.RUnlock()

	if !cached {
		wl, returnColumns := columns.InsertColumnSet(
			userAuthAllColumns,
			userAuthColumnsWithDefault,
			userAuthColumnsWithoutDefault,
			nzDefaults,
		)

		cache.valueMapping, err = queries.BindMapping(userAuthType, userAuthMapping, wl)
		if err != nil {
			return err
		}
		cache.retMapping, err = queries.BindMapping(userAuthType, userAuthMapping, returnColumns)
		if err != nil {
			return err
		}
		if len(wl) != 0 {
			cache.query = fmt.Sprintf("INSERT INTO \"user_auth\" (\"%s\") %%sVALUES (%s)%%s", strings.Join(wl, "\",\""), strmangle.Placeholders(dialect.UseIndexPlaceholders, len(wl), 1, 1))
		} else {
			cache.query = "INSERT INTO \"user_auth\" %sDEFAULT VALUES%s"
		}

		var queryOutput, queryReturning string

		if len(cache.retMapping) != 0 {
			queryReturning = fmt.Sprintf(" RETURNING \"%s\"", strings.Join(returnColumns, "\",\""))
		}

		cache.query = fmt.Sprintf(cache.query, queryOutput, queryReturning)
	}

	value := reflect.Indirect(reflect.ValueOf(o))
	vals := queries.ValuesFromMapping(value, cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, vals)
	}

	if len(cache.retMapping) != 0 {
		err = exec.QueryRowContext(ctx, cache.query, vals...).Scan(queries.PtrsFromMapping(value, cache.retMapping)...)
	} else {
		_, err = exec.ExecContext(ctx, cache.query, vals...)
	}

	if err != nil {
		return errors.Wrap(err, "model: unable to insert into user_auth")
	}

	if !cached {
		userAuthInsertCacheMut.Lock()
		userAuthInsertCache[key] = cache
		userAuthInsertCacheMut.Unlock()
	}

	return nil
}

// Update uses an executor to update the UserAuth.
// See boil.Columns.UpdateColumnSet documentation to understand column list inference for updates.
// Update does not automatically update the record in case of default values. Use .Reload() to refresh the records.
func (o *UserAuth) Update(ctx context.Context, exec boil.ContextExecutor, columns boil.Columns) (int64, error) {
	var err error
	key := makeCacheKey(columns, nil)
	userAuthUpdateCacheMut.RLock()
	cache, cached := userAuthUpdateCache[key]
	userAuthUpdateCacheMut.RUnlock()

	if !cached {
		wl := columns.UpdateColumnSet(
			userAuthAllColumns,
			userAuthPrimaryKeyColumns,
		)

		if !columns.IsWhitelist() {
			wl = strmangle.SetComplement(wl, []string{"created_at"})
		}
		if len(wl) == 0 {
			return 0, errors.New("model: unable to update user_auth, could not build whitelist")
		}

		cache.query = fmt.Sprintf("UPDATE \"user_auth\" SET %s WHERE %s",
			strmangle.SetParamNames("\"", "\"", 1, wl),
			strmangle.WhereClause("\"", "\"", len(wl)+1, userAuthPrimaryKeyColumns),
		)
		cache.valueMapping, err = queries.BindMapping(userAuthType, userAuthMapping, append(wl, userAuthPrimaryKeyColumns...))
		if err != nil {
			return 0, err
		}
	}

	values := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), cache.valueMapping)

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, cache.query)
		fmt.Fprintln(writer, values)
	}
	var result sql.Result
	result, err = exec.ExecContext(ctx, cache.query, values...)
	if err != nil {
		return 0, errors.Wrap(err, "model: unable to update user_auth row")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "model: failed to get rows affected by update for user_auth")
	}

	if !cached {
		userAuthUpdateCacheMut.Lock()
		userAuthUpdateCache[key] = cache
		userAuthUpdateCacheMut.Unlock()
	}

	return rowsAff, nil
}

// UpdateAll updates all rows with the specified column values.
func (q userAuthQuery) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) (int64, error) {
	queries.SetUpdate(q.Query, cols)

	result, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return 0, errors.Wrap(err, "model: unable to update all for user_auth")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "model: unable to retrieve rows affected for user_auth")
	}

	return rowsAff, nil
}

// UpdateAll updates all rows with the specified column values, using an executor.
func (o UserAuthSlice) UpdateAll(ctx context.Context, exec boil.ContextExecutor, cols M) (int64, error) {
	ln := int64(len(o))
	if ln == 0 {
		return 0, nil
	}

	if len(cols) == 0 {
		return 0, errors.New("model: update all requires at least one column argument")
	}

	colNames := make([]string, len(cols))
	args := make([]interface{}, len(cols))

	i := 0
	for name, value := range cols {
		colNames[i] = name
		args[i] = value
		i++
	}

	// Append all of the primary key values for each column
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), userAuthPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := fmt.Sprintf("UPDATE \"user_auth\" SET %s WHERE %s",
		strmangle.SetParamNames("\"", "\"", 1, colNames),
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), len(colNames)+1, userAuthPrimaryKeyColumns, len(o)))

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "model: unable to update all in userAuth slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "model: unable to retrieve rows affected all in update all userAuth")
	}
	return rowsAff, nil
}

// Delete deletes a single UserAuth record with an executor.
// Delete will match against the primary key column to find the record to delete.
func (o *UserAuth) Delete(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if o == nil {
		return 0, errors.New("model: no UserAuth provided for delete")
	}

	args := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(o)), userAuthPrimaryKeyMapping)
	sql := "DELETE FROM \"user_auth\" WHERE \"id\"=$1"

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args...)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "model: unable to delete from user_auth")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "model: failed to get rows affected by delete for user_auth")
	}

	return rowsAff, nil
}

// DeleteAll deletes all matching rows.
func (q userAuthQuery) DeleteAll(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if q.Query == nil {
		return 0, errors.New("model: no userAuthQuery provided for delete all")
	}

	queries.SetDelete(q.Query)

	result, err := q.Query.ExecContext(ctx, exec)
	if err != nil {
		return 0, errors.Wrap(err, "model: unable to delete all from user_auth")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "model: failed to get rows affected by deleteall for user_auth")
	}

	return rowsAff, nil
}

// DeleteAll deletes all rows in the slice, using an executor.
func (o UserAuthSlice) DeleteAll(ctx context.Context, exec boil.ContextExecutor) (int64, error) {
	if len(o) == 0 {
		return 0, nil
	}

	var args []interface{}
	for _, obj := range o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), userAuthPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "DELETE FROM \"user_auth\" WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 1, userAuthPrimaryKeyColumns, len(o))

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, args)
	}
	result, err := exec.ExecContext(ctx, sql, args...)
	if err != nil {
		return 0, errors.Wrap(err, "model: unable to delete all from userAuth slice")
	}

	rowsAff, err := result.RowsAffected()
	if err != nil {
		return 0, errors.Wrap(err, "model: failed to get rows affected by deleteall for user_auth")
	}

	return rowsAff, nil
}

// Reload refetches the object from the database
// using the primary keys with an executor.
func (o *UserAuth) Reload(ctx context.Context, exec boil.ContextExecutor) error {
	ret, err := FindUserAuth(ctx, exec, o.ID)
	if err != nil {
		return err
	}

	*o = *ret
	return nil
}

// ReloadAll refetches every row with matching primary key column values
// and overwrites the original object slice with the newly updated slice.
func (o *UserAuthSlice) ReloadAll(ctx context.Context, exec boil.ContextExecutor) error {
	if o == nil || len(*o) == 0 {
		return nil
	}

	slice := UserAuthSlice{}
	var args []interface{}
	for _, obj := range *o {
		pkeyArgs := queries.ValuesFromMapping(reflect.Indirect(reflect.ValueOf(obj)), userAuthPrimaryKeyMapping)
		args = append(args, pkeyArgs...)
	}

	sql := "SELECT \"user_auth\".* FROM \"user_auth\" WHERE " +
		strmangle.WhereClauseRepeated(string(dialect.LQ), string(dialect.RQ), 1, userAuthPrimaryKeyColumns, len(*o))

	q := queries.Raw(sql, args...)

	err := q.Bind(ctx, exec, &slice)
	if err != nil {
		return errors.Wrap(err, "model: unable to reload all in UserAuthSlice")
	}

	*o = slice

	return nil
}

// UserAuthExists checks if the UserAuth row exists.
func UserAuthExists(ctx context.Context, exec boil.ContextExecutor, iD int64) (bool, error) {
	var exists bool
	sql := "select exists(select 1 from \"user_auth\" where \"id\"=$1 limit 1)"

	if boil.IsDebug(ctx) {
		writer := boil.DebugWriterFrom(ctx)
		fmt.Fprintln(writer, sql)
		fmt.Fprintln(writer, iD)
	}
	row := exec.QueryRowContext(ctx, sql, iD)

	err := row.Scan(&exists)
	if err != nil {
		return false, errors.Wrap(err, "model: unable to check if user_auth exists")
	}

	return exists, nil
}

// Exists checks if the UserAuth row exists.
func (o *UserAuth) Exists(ctx context.Context, exec boil.ContextExecutor) (bool, error) {
	return UserAuthExists(ctx, exec, o.ID)
}
